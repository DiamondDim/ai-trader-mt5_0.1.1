import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, f1_score
import joblib
import os
from typing import Optional
import warnings

warnings.filterwarnings('ignore')


class ModelBuilder:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π"""

    def __init__(self, config: dict):
        self.config = config
        self.model = None
        self.feature_importance_ = None

    def create_model(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        model_config = self.config.get('model', {})
        model_type = model_config.get('model_type', 'GradientBoosting')

        print(f"–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_type}")

        if model_type == "GradientBoosting":
            model_params = model_config.get('model_params', {})
            self.model = GradientBoostingClassifier(
                n_estimators=model_params.get('n_estimators', 100),
                max_depth=model_params.get('max_depth', 3),
                learning_rate=model_params.get('learning_rate', 0.1),
                random_state=model_params.get('random_state', 42)
            )
        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º GradientBoosting
            self.model = GradientBoostingClassifier(
                n_estimators=100,
                max_depth=3,
                learning_rate=0.1,
                random_state=42
            )

        return self.model

    def train_model(self, data: pd.DataFrame, symbol: str, feature_engineer) -> Optional[str]:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á
            print("–ù–∞—á–∞–ª–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
            features_df = feature_engineer.prepare_features(data, symbol)
            feature_names = feature_engineer.get_feature_names()

            if len(features_df) == 0:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return None

            # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ü–µ–Ω—ã)
            features_df = self._create_target(features_df)

            # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN
            features_df = features_df.dropna()

            if len(features_df) < 100:
                print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
                return None

            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            X = features_df[feature_names]
            y = features_df['target']

            print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(X)} samples, {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
            test_size = self.config.get('ml', {}).get('test_size', 0.3)
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, shuffle=False
            )

            print(f"üìä –î–∞–Ω–Ω—ã–µ: train={len(X_train)}, test={len(X_test)}")

            # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model = self.create_model()

            print("–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...")
            model.fit(X_train, y_train)

            # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
            cv_scores = cross_val_score(model, X_train, y_train, cv=5)
            print(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. CV Accuracy: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")

            # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            y_pred = model.predict(X_test)
            test_accuracy = accuracy_score(y_test, y_pred)
            test_f1 = f1_score(y_test, y_pred, average='weighted')

            print(f"–¢–µ—Å—Ç–æ–≤–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {test_accuracy:.4f}")
            print(f"Test F1-Score: {test_f1:.4f}")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if hasattr(model, 'feature_importances_'):
                self.feature_importance_ = pd.DataFrame({
                    'feature': feature_names,
                    'importance': model.feature_importances_
                }).sort_values('importance', ascending=False)

                print("\nüéØ –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
                for i, row in self.feature_importance_.head(10).iterrows():
                    print(f"   {row['feature']}: {row['importance']:.4f}")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_path = self.config.get('ml', {}).get('model_path', 'models/trained_model.pkl')
            os.makedirs(os.path.dirname(model_path), exist_ok=True)

            joblib.dump(model, model_path)
            print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {model_path}")

            self.model = model
            return model_path

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _create_target(self, df: pd.DataFrame, horizon: int = 5) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
        # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: 1 –µ—Å–ª–∏ —Ü–µ–Ω–∞ –≤—ã—Ä–∞—Å—Ç–µ—Ç —á–µ—Ä–µ–∑ horizon –±–∞—Ä–æ–≤, 0 –µ—Å–ª–∏ —É–ø–∞–¥–µ—Ç
        df['future_price'] = df['close'].shift(-horizon)
        df['price_change'] = (df['future_price'] - df['close']) / df['close']

        # –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: 1 –µ—Å–ª–∏ —Ä–æ—Å—Ç > 0, 0 –∏–Ω–∞—á–µ
        df['target'] = (df['price_change'] > 0).astype(int)

        # –£–¥–∞–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ horizon —Å—Ç—Ä–æ–∫ (—É –Ω–∏—Ö –Ω–µ—Ç future_price)
        df = df[:-horizon]

        return df

    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            model_path = self.config.get('ml', {}).get('model_path', 'models/trained_model.pkl')

            if not os.path.exists(model_path):
                print(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
                return None

            self.model = joblib.load(model_path)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}")
            return self.model

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return None

    def predict(self, features):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if self.model is None:
            print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None

        try:
            prediction = self.model.predict(features)
            probabilities = self.model.predict_proba(features)
            return prediction, probabilities
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return None
